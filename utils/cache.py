# coding=utf-8
import logging
import functools
from django.db import models
from django.core.cache import cache
from django.utils import decorators
from oecloud_dashboard.api.base import APIDictWrapper, APIResourceWrapper
from django_redis import get_redis_connection


PRODUCT = 'oecloud'

logger = logging.getLogger(__name__)


def _get_obj_key(obj, k='id'):
    """è·å–å¯¹è±¡çš„ä¸»é”®"""
    if isinstance(obj, dict):
        return obj.get(k) or obj.get('id') or obj.get('uuid')
    return getattr(obj, k, getattr(obj, 'id', None) or getattr(obj, 'uuid', None))


def get_obj_value(obj, k=None, v=None, debug=False):
    """
    è·å–å¯¹è±¡ä¸­æŒ‡å®šå­—æ®µçš„é”®å€¼

    :param k: å¯¹è±¡ä¸­å¯¹åº”çš„ä¸€ä¸ªkey
    :param v: è·å–kå¯¹åº”çš„å€¼å¤±è´¥çš„æ—¶å€™è¿”å›çš„é»˜è®¤å€¼
    """
    if k is None:
        return obj
    elif hasattr(obj, k):
        value = getattr(obj, k)
        return callable(value) and value() or value
    elif isinstance(obj, dict):
        return obj.get(k)
    elif isinstance(obj, (APIDictWrapper, APIResourceWrapper)):
        d = obj.to_dict()
        return d.get(k)
    else:
        return v


def generate_cachekey(prefix='', suffix='', **kw):
    """
    ç”Ÿæˆç¼“å­˜çš„é”®

    :param prefix: ç¼“å­˜çš„keyçš„å‰ç¼€
    :param suffix: ç¼“å­˜çš„keyçš„åç¼€
    :param kw: æš‚æ—¶æ²¡ç”¨åˆ°çš„å…¶ä»–å‚æ•°
    """
    # if not (prefix is not None and bool(suffix) is not False):
    #     return
    assert prefix is not None, 'prefix is not given'
    assert bool(suffix) is not False, 'suffix is not given'
    return '%s-%s::%s' % (PRODUCT, prefix or 'CACHE', suffix)


def _get_cachevalue(obj, prefix=None, suffix=None, which_key=None, debug=False, **kw):
    cachevalue = get_obj_value(obj, which_key)
    if not (cachevalue and isinstance(cachevalue, (dict, APIResourceWrapper, APIDictWrapper, models.Model))):
        # æ­¤å¤„çš„ç›®çš„åœ¨äºå½“æŸä¸ªå¯¹è±¡æ›´æ–°äº†æ—¶å€™å¯¹åº”çš„'æ›´æ–°/åˆ é™¤'ç¼“å­˜
        # æ‰€ä»¥å¦‚æœå¯¹è±¡ä¼ è¿›æ¥äº†, ä½†æ˜¯å€¼ä¸å¯¹, é‚£ä¹ˆéœ€è¦æŠŠæ—§çš„ç¼“å­˜æ¸…ç†æ‰
        if suffix:
            cachekey = generate_cachekey(prefix, suffix)
            cache.delete(cachekey)
        logger.debug(u'ğŸ˜€ğŸ˜€ğŸ˜€cache_set_obj::BAD obj=%s\n'
                     u'ğŸ˜€ğŸ˜€ğŸ˜€cache_set_obj::delete cachekey=%s' % (obj, cachekey))
        return

    # ç›´æ¥ä½¿ç”¨APIResourceWrapperçš„è¯åœ¨åºåˆ—åŒ–çš„æ—¶å€™ä¼šå‡ºé—®é¢˜
    # è¿™é‡Œå…ˆæŠŠå†…éƒ¨çš„æ•°æ®ç±»å‹è½¬æ¢ä¸ºdict, ç„¶ååœ¨to_dictä¸Šé¢åšä¸€ç‚¹å·¥ä½œ
    if isinstance(cachevalue, APIResourceWrapper):
        try:
            cachevalue = cachevalue.__class__(cachevalue.to_dict())
        except:
            cachevalue = cachevalue.to_dict()
    return cachevalue


def find_obj_by_path(original, path, debug=False):
    if isinstance(original, (APIDictWrapper, APIResourceWrapper)):
        base = original.to_dict()
    else:
        base = original
    objs = []
    paths = path.split('::')

    key = paths[0]
    paths = paths[1:]
    if debug:
        logger.debug('base=%s, type=%s' % (base, type(base)))

    if isinstance(base, dict):
        base = base.get(key, {})
    elif isinstance(base, (str, unicode)):
        return [base]

    if isinstance(base, list):
        # logger.error('list base=%s' % base)
        for obj in base:
            objs.extend(find_obj_by_path(obj, '::'.join(paths)))
    elif isinstance(base, dict) and base:
        # logger.error('dict base=%s' % base)
        objs.extend(find_obj_by_path(base, '::'.join(paths)))
    else:
        # logger.error('else base=%s' % base)
        objs.append(base)
    return objs


def delete_related_cache(obj=None, prefix=None, suffix=None, which_key=None, debug=False, **kw):
    """
    å…³è”å¯¹è±¡ç¼“å­˜æ›´æ–°

    ç”¨äºåˆ é™¤å¤±æ•ˆå…³è”ç¼“å­˜æ•°æ®(ä¾‹å¦‚å­ç½‘æ›´æ–°äº†éœ€è¦æ›´æ–°å­ç½‘æ‰€åœ¨çš„ç½‘ç»œç¼“å­˜,
    è¿™é‡Œç›´æ¥åˆ é™¤æ‰æ—§ç¼“å­˜, ä¸‹æ¬¡å–å€¼é‡æ–°è®¾ç½®ç¼“å­˜)

    :param obj: dict, APIResourceWrapperæˆ–APIDictWrapperç±»å‹çš„å¯¹è±¡
    :param prefix: ç¼“å­˜çš„keyçš„å‰ç¼€ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ `obj` ä½¿ç”¨uuidä¸»é”®çš„æ—¶å€™flagä¸éœ€è¦æä¾›, ä½¿ç”¨idçš„åˆ™éœ€è¦æä¾›ä¸€ä¸ªæ ‡è¯†ä½
    :param suffix: ç¼“å­˜çš„keyçš„åç¼€ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ `obj` çš„ä¸»é”®ä½œä¸ºæ­¤å­—æ®µçš„å€¼
    :param which_key: ä»objé‡Œé¢å–åˆ°which_keyçš„å€¼ä½œä¸ºç¼“å­˜çš„é”®å€¼çš„ä¸€éƒ¨åˆ†
        è¯¥å­—æ®µçš„ç”¨æ³•å¯èƒ½æ˜¯ obj.which_key,obj['which_key']æˆ–è€…obj.which_key()
    """
    relateds = kw.get('related')
    logged_msg = []
    logged_msg.append('obj=%s\n'
                      'prefix=%s\n'
                      'suffix=%s\n'
                      'which_key=%s\n'
                      'relateds=%s\n' % (
                          type(obj), prefix, suffix, which_key, relateds
                      ))

    if relateds:
        relateds = [r for r in relateds.split('|') if r]
        for related in relateds:
            if not obj:
                cache_key = generate_cachekey(prefix, suffix)
                obj = cache.get(cache_key)
            cachevalue = _get_cachevalue(obj, prefix, suffix, which_key, debug, **kw)
            related_prefix, related_key = related.split('::', 1)
            lst = []
            if '::' not in related_key:
                lst = _get_obj_key(cachevalue, related_key)
                lst = isinstance(lst, list) and lst or [lst]

            else:
                lst = find_obj_by_path(cachevalue, related_key)
                if kw.get('debug'):
                    logged_msg.append('will be deleted: related_prefix=%s, keys=%s\n' % (related_prefix, lst))
                lst = [i for i in lst if i]

            for related_obj_id in lst:
                if not related_obj_id:
                    continue
                related_cache_key = generate_cachekey(related_prefix, related_obj_id, **kw)
                cache.delete(related_cache_key)
                if debug:
                    logged_msg.append(u'GET related_cache_key=%s\n' % related_cache_key)
    if debug:
        logger.debug(''.join(logged_msg))


def redis_naive_delete_cache(ids):
    con = get_redis_connection("default")
    dirty_keys = []
    for id in ids:
        keys = con.keys('*%s*' % id)
        dirty_keys.extend(keys)
    if dirty_keys:
        logger.debug('redis_naive_delete_cache keys=%s' % dirty_keys)
        con.delete(*dirty_keys)


related_status_map = {
    # ä»»æ„å¥åº·ç›‘æ§å¤„äºéä¸´ç•ŒçŠ¶æ€
    'lb-pool': lambda obj: any(map(
        lambda hm: hm and str(hm.get('status')).lower().startswith('pending'),
        obj and obj.get('health_monitors_status') or []
    ))
}


def cache_set_obj(obj, prefix=None, suffix=None, which_key=None, debug=False, **kw):
    """
    å¯¹è±¡ç¼“å­˜

    ç¼“å­˜å¯ä»¥ç”¨æ¥ç¼“å­˜çš„å¯¹è±¡, è¿”å›è¯¥å¯¹è±¡å’Œå…¶å¯¹åº”çš„ç¼“å­˜é”®

    :param obj: dict, APIResourceWrapperæˆ–APIDictWrapperç±»å‹çš„å¯¹è±¡
    :param prefix: ç¼“å­˜çš„keyçš„å‰ç¼€ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ `obj` ä½¿ç”¨uuidä¸»é”®çš„æ—¶å€™flagä¸éœ€è¦æä¾›, ä½¿ç”¨idçš„åˆ™éœ€è¦æä¾›ä¸€ä¸ªæ ‡è¯†ä½
    :param suffix: ç¼“å­˜çš„keyçš„åç¼€ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ `obj` çš„ä¸»é”®ä½œä¸ºæ­¤å­—æ®µçš„å€¼
    :param which_key: ä»objé‡Œé¢å–åˆ°which_keyçš„å€¼ä½œä¸ºç¼“å­˜çš„é”®å€¼çš„ä¸€éƒ¨åˆ†
        è¯¥å­—æ®µçš„ç”¨æ³•å¯èƒ½æ˜¯ obj.which_key,obj['which_key']æˆ–è€…obj.which_key()
    """
    if not suffix:
        suffix = _get_obj_key(obj)
    cachekey = generate_cachekey(prefix, suffix)
    cachevalue = None
    cachevalue = _get_cachevalue(obj, prefix, suffix, which_key, debug, **kw)
    obj_status = getattr(cachevalue, 'status', '') or getattr(cachevalue, 'status', '')

    if str(obj_status).lower().startswith('pending') or str(obj_status).lower().endswith('ing'):
        if debug:
            logger.debug(u'stop create cache because cache in %s status\n'
                         u'DEL cachekey=%s \n' % (obj_status, cachekey))
        cache.delete(cachekey)

    elif related_status_map.has_key(prefix) and related_status_map[prefix](obj):
        if debug:
            logger.debug(u'stop create cache because related cache in PENDING status\n'
                         u'DEL cachekey=%s\n'
                         u'obj=%s\n' % (cachekey, obj))
        cache.delete(cachekey)

    else:
        cache.set(cachekey, cachevalue, 60 * 60 * 4)
        if debug:
            logger.debug(u'SET cachekey=%s\ncachevalue=%s' % (cachekey, cachevalue))
    delete_related_cache(obj, prefix, suffix, which_key, debug=debug, **kw)
    return obj, cachevalue


def cache_get_obj(prefix=None, suffix=None, debug=False, **kw):
    """ç¼“å­˜è·å–"""
    cachekey = generate_cachekey(prefix, suffix)
    cached_obj = cache.get(cachekey)
    if debug:
        logger.debug(
            'cachekey=%s\n'
            'cached_value=%s\n' % (cachekey, type(cached_obj)))

    if str(getattr(cached_obj, 'status', '')).lower().startswith('pending') or str(getattr(cached_obj, 'status', '')).lower().endswith('ing'):
        logger.warning(u'cache_get_obj::stop get cache\n'
                       u'cache_get_obj::delete cachekey=%s\n'
                       u'cache_get_obj::cached_obj=%s\n' % (cachekey, cached_obj))
        cache.delete(cachekey)
        return
    elif related_status_map.has_key(prefix) and related_status_map[prefix](cached_obj):
        logger.warning(u'cache_get_obj::stop get cache because related cache in PENDING status\n'
                       u'obj=%s\n'
                       u'cache_get_obj::delete cachekey=%s\n'
                       u'cache_get_obj::cached_obj=%s ' % (cached_obj, cachekey, cached_obj))
        cache.delete(cachekey)
        return

    return cached_obj


def _cache_handle_base(mode, **wrapper_kwargs):
    """
    å¯¹è±¡è¢«æ›´æ–°åå¯¹åº”çš„æ›´æ–°ç¼“å­˜

    ä¸€äº›å¸¸ç”¨å‚æ•°
    :param prefix: ç¼“å­˜çš„keyçš„å‰ç¼€
    :param suffix: ç¼“å­˜çš„keyçš„åç¼€
    :param suffix_key: ç¼“å­˜çš„keyçš„åç¼€åœ¨ä¼ å‚ä¸­çš„åå­—(ä½œç”¨äºgetfunc(self, *args, **kw) å½¢å¼)
    :param which_key: ç”¨æ¥ç¼“å­˜çš„éƒ¨åˆ†(obj.which_key)
    :param anonymous(boolean): ç›®æ ‡å‡½æ•°çš„è°ƒç”¨æ–¹å¼
        True: ä½œç”¨äºå½¢å¦‚ getfunc(self, *args, **kw) çš„å‡½æ•°
        False: ä½œç”¨äºå½¢å¦‚ getfunc(self, obj_id, *args, **kw) çš„å‡½æ•°
    :param related: å…³è”çš„èµ„æº(prefix::key)
        å…³è”çš„èµ„æº(å½“å‰èµ„æºæ›´æ–°åå…³è”èµ„æºç¼“å­˜è¢«åˆ é™¤)
    :param debug: è°ƒè¯•æ¨¡å¼
    """
    import api.jobs

    def _wrapper(func):

        @functools.wraps(func, assigned=decorators.available_attrs(func))
        def _inner(self, *args, **kw):
            logged_msg = []
            inner_kwargs = wrapper_kwargs.copy()
            use_cache = kw.pop('use_cache', True)
            debug = inner_kwargs.get('debug')
            cached_obj = None
            if mode != 'create':
                suffix = kw.get(inner_kwargs.get('suffix_key')) or wrapper_kwargs.get(
                    inner_kwargs.get('suffix_key') or 'suffix')
                suffix = suffix or args and args[0] or None
                inner_kwargs['suffix'] = suffix
            logged_msg.append(
                'mode=%s\n'
                'call=%s\n'
                'args=%s\n'
                'kw=%s\n'
                'use_cache=%s\n'
                'kwargs=%s\n' % (
                    mode, func.__name__, args, kw, use_cache, inner_kwargs
                ))

            # list/get çš„æ—¶å€™ä¼˜å…ˆä»ç¼“å­˜ä¸­è·å–è¿”å›å€¼, æ²¡æœ‰çš„æ—¶å€™æ‰ä¼šè°ƒç”¨func
            if mode == 'list':
                obj = func(self, *args, **kw)
                prefix = inner_kwargs.pop('prefix')
                suffix_key_path = inner_kwargs.pop('suffix_key', 'id')
                diff_key_path = inner_kwargs.get('diff_key', 'status')
                logged_msg.append('ADD api.jobs.cache_diff_and_destroy')
                api.jobs.rq_run(api.jobs.cache_diff_and_destroy, obj, prefix,
                                suffix_key_path, diff_key_path, **inner_kwargs)
            elif mode == 'get':
                obj = use_cache and cache_get_obj(**inner_kwargs)
                if not obj:
                    obj = func(self, *args, **kw)
                    cache_set_obj(obj, **inner_kwargs)

            # create/update/delete çš„æ—¶å€™éœ€è¦å¯¹åº”æ›´æ–°ç¼“å­˜
            elif mode in ('create', 'update', 'delete'):
                try:
                    cachekey = generate_cachekey(**inner_kwargs)
                    cached_obj = cache.get(cachekey)
                    delete_related_cache(debug=True, **inner_kwargs)
                except:
                    pass
                obj = func(self, *args, **kw)
                if mode == 'create' and not inner_kwargs.get('suffix'):
                    inner_kwargs.update({'suffix': _get_obj_key(obj)})

                if mode in ('create', 'update') and obj:
                    cache_set_obj(obj, **inner_kwargs)

                else:
                    try:
                        logged_msg.append('inner_kwargs=%s\n' % inner_kwargs)
                        delete_related_cache(obj, **inner_kwargs)
                        cachekey = generate_cachekey(**inner_kwargs)
                        cache.delete(cachekey)
                        logged_msg.append('DEL cache=%s\n' % cachekey)
                    except:
                        pass

                logged_msg.append(
                    'cached_obj=%(cached_obj)s\n'
                    'output obj=%(obj)s\n' % {
                        'cached_obj': cached_obj,
                        'obj': obj
                    })
            if debug:
                logger.debug(''.join(logged_msg) + '\n' + '#' * 80)
            return obj

        assert mode in ('list', 'get', 'create', 'update', 'delete')
        return _inner
    return _wrapper


# decorators
cache_handle_list = functools.partial(_cache_handle_base, mode='list')
cache_handle_get = functools.partial(_cache_handle_base, mode='get')
cache_handle_create = functools.partial(_cache_handle_base, mode='create')
cache_handle_update = functools.partial(_cache_handle_base, mode='update')
cache_handle_delete = functools.partial(_cache_handle_base, mode='delete')
